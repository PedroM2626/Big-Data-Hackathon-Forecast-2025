{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Modelo de Previs√£o de Vendas (Forecast) - One-Click Order\n",
    "\n",
    "## Sistema para prever quantidade semanal de vendas por PDV/SKU\n",
    "\n",
    "**Objetivo:** Apoiar reposi√ß√£o de estoque para 5 semanas de janeiro/2023  \n",
    "**Base:** Hist√≥rico de vendas de 2022  \n",
    "**Contexto:** One-Click Order - Sistema de reposi√ß√£o autom√°tica\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Etapas do Projeto:\n",
    "1. **Carregamento e An√°lise dos Dados**\n",
    "2. **Feature Engineering**\n",
    "3. **Modelagem e Valida√ß√£o**\n",
    "4. **Gera√ß√£o de Previs√µes**\n",
    "5. **An√°lise de Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o das bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Bibliotecas para machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
    "print(\"üéØ OBJETIVO: Modelo de Forecast para Reposi√ß√£o de Estoque\")\n",
    "print(\"üìÖ META: Prever vendas para 5 semanas de janeiro/2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìÇ Carregamento dos Dados Hist√≥ricos\n",
    "\n",
    "Vamos carregar os dados hist√≥ricos de vendas de 2022. O sistema tenta carregar os arquivos parquet reais, mas se houver problemas, utiliza dados simulados realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sales_data():\n",
    "    \"\"\"Carregar dados de vendas dos arquivos parquet ou criar dados simulados\"\"\"\n",
    "    print(\"üìÇ CARREGAMENTO DOS DADOS DE VENDAS 2022\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Caminhos dos arquivos\n",
    "    arquivos = [\n",
    "        \"data/raw/part-00000-tid-6364321654468257203-dc13a5d6-36ae-48c6-a018-37d8cfe34cf6-263-1-c000.snappy.parquet\",\n",
    "        \"data/raw/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet\",\n",
    "        \"data/raw/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet\"\n",
    "    ]\n",
    "    \n",
    "    dataframes = []\n",
    "    use_simulated = False\n",
    "    \n",
    "    for i, arquivo in enumerate(arquivos):\n",
    "        if os.path.exists(arquivo):\n",
    "            try:\n",
    "                df_temp = pd.read_parquet(arquivo)\n",
    "                dataframes.append(df_temp)\n",
    "                print(f\"‚úì Arquivo {i+1}: {df_temp.shape[0]} registros carregados\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro no arquivo {i+1}: {e}\")\n",
    "                use_simulated = True\n",
    "                break\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Arquivo {i+1} n√£o encontrado\")\n",
    "            use_simulated = True\n",
    "            break\n",
    "    \n",
    "    if use_simulated or not dataframes:\n",
    "        print(\"\\nüîÑ Utilizando dados simulados realistas para demonstra√ß√£o\")\n",
    "        return create_simulated_data()\n",
    "    else:\n",
    "        df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "        print(f\"\\n‚úÖ Dados reais carregados: {df_combined.shape[0]} registros\")\n",
    "        return df_combined\n",
    "\n",
    "def create_simulated_data():\n",
    "    \"\"\"Criar dados hist√≥ricos simulados realistas para 2022\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # PDVs e SKUs para simula√ß√£o\n",
    "    pdvs = [1023, 1045, 1067, 1089, 1012, 1156, 1198, 1234, 1345, 1456]\n",
    "    skus = [f\"SKU_{i:04d}\" for i in range(1001, 1101)]  # 100 SKUs\n",
    "    \n",
    "    # Gerar dados para cada semana de 2022\n",
    "    for semana in range(1, 53):  # 52 semanas\n",
    "        for pdv in pdvs:\n",
    "            # Cada PDV tem entre 15-25 SKUs diferentes por semana\n",
    "            skus_ativos = np.random.choice(skus, size=np.random.randint(15, 26), replace=False)\n",
    "            \n",
    "            for sku in skus_ativos:\n",
    "                # Fator sazonal (vendas maiores no fim do ano)\n",
    "                seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * (semana - 40) / 52)\n",
    "                \n",
    "                # Fator PDV (alguns PDVs vendem mais)\n",
    "                pdv_factor = 1.0\n",
    "                if pdv in [1023, 1045, 1198]:  # PDVs de alto volume\n",
    "                    pdv_factor = 1.5\n",
    "                elif pdv in [1067, 1234]:  # PDVs de baixo volume\n",
    "                    pdv_factor = 0.7\n",
    "                \n",
    "                # Fator SKU (alguns produtos s√£o mais populares)\n",
    "                sku_num = int(sku.split('_')[1])\n",
    "                if sku_num % 10 == 1:  # SKUs \"premium\"\n",
    "                    sku_factor = 1.3\n",
    "                elif sku_num % 10 == 9:  # SKUs \"promocionais\"\n",
    "                    sku_factor = 1.8\n",
    "                else:\n",
    "                    sku_factor = 1.0\n",
    "                \n",
    "                # Quantidade base com varia√ß√£o aleat√≥ria\n",
    "                base_qty = np.random.poisson(12)\n",
    "                final_qty = max(1, int(base_qty * seasonal_factor * pdv_factor * sku_factor))\n",
    "                \n",
    "                data.append({\n",
    "                    'ano': 2022,\n",
    "                    'semana': semana,\n",
    "                    'pdv': pdv,\n",
    "                    'sku': sku,\n",
    "                    'quantidade': final_qty\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Carregar os dados\n",
    "df_historical = load_sales_data()\n",
    "print(f\"\\nüìä Dataset final: {df_historical.shape[0]:,} registros, {df_historical.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üìà An√°lise Explorat√≥ria dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(df):\n",
    "    \"\"\"An√°lise explorat√≥ria dos dados\"\"\"\n",
    "    print(\"üìä AN√ÅLISE EXPLORAT√ìRIA DOS DADOS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_vendas = df['quantidade'].sum()\n",
    "    media_vendas = df['quantidade'].mean()\n",
    "    \n",
    "    print(f\"üìä Total de registros: {len(df):,}\")\n",
    "    print(f\"üè™ PDVs √∫nicos: {df['pdv'].nunique()}\")\n",
    "    print(f\"üì¶ SKUs √∫nicos: {df['sku'].nunique()}\")\n",
    "    print(f\"üìà Total de vendas: {total_vendas:,} unidades\")\n",
    "    print(f\"üí° M√©dia por registro: {media_vendas:.1f} unidades\")\n",
    "    print(f\"üìä Mediana: {df['quantidade'].median():.1f} unidades\")\n",
    "    print(f\"üìä Desvio padr√£o: {df['quantidade'].std():.1f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Executar an√°lise\n",
    "df_analyzed = analyze_data(df_historical)\n",
    "\n",
    "# Mostrar amostra dos dados\n",
    "print(\"\\nüìã Amostra dos dados:\")\n",
    "display(df_historical.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de top performers\n",
    "print(\"üèÜ TOP PERFORMERS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Top 10 PDVs\n",
    "top_pdvs = df_historical.groupby('pdv')['quantidade'].sum().nlargest(10)\n",
    "print(\"\\nüè™ TOP 10 PDVs por volume:\")\n",
    "for i, (pdv, qty) in enumerate(top_pdvs.items(), 1):\n",
    "    print(f\"   {i:2d}. PDV {pdv}: {qty:,} unidades\")\n",
    "\n",
    "# Top 10 SKUs\n",
    "top_skus = df_historical.groupby('sku')['quantidade'].sum().nlargest(10)\n",
    "print(\"\\nüì¶ TOP 10 SKUs por volume:\")\n",
    "for i, (sku, qty) in enumerate(top_skus.items(), 1):\n",
    "    print(f\"   {i:2d}. {sku}: {qty:,} unidades\")\n",
    "\n",
    "# An√°lise sazonal\n",
    "vendas_por_semana = df_historical.groupby('semana')['quantidade'].sum()\n",
    "vendas_por_trimestre = df_historical.groupby((df_historical['semana'] - 1) // 13 + 1)['quantidade'].sum()\n",
    "\n",
    "print(\"\\nüìÖ An√°lise Sazonal:\")\n",
    "print(\"Vendas por trimestre:\")\n",
    "for trimestre, vendas in vendas_por_trimestre.items():\n",
    "    print(f\"   Q{trimestre}: {vendas:,} unidades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('An√°lise Explorat√≥ria - Dados Hist√≥ricos 2022', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Vendas por semana\n",
    "axes[0, 0].plot(vendas_por_semana.index, vendas_por_semana.values, marker='o', linewidth=2)\n",
    "axes[0, 0].set_title('Vendas Totais por Semana (2022)')\n",
    "axes[0, 0].set_xlabel('Semana')\n",
    "axes[0, 0].set_ylabel('Quantidade Total')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribui√ß√£o de quantidades\n",
    "axes[0, 1].hist(df_historical['quantidade'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Distribui√ß√£o das Quantidades Vendidas')\n",
    "axes[0, 1].set_xlabel('Quantidade')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "# 3. Top 10 PDVs\n",
    "top_pdvs_plot = top_pdvs.head(10)\n",
    "axes[1, 0].barh(range(len(top_pdvs_plot)), top_pdvs_plot.values)\n",
    "axes[1, 0].set_yticks(range(len(top_pdvs_plot)))\n",
    "axes[1, 0].set_yticklabels([f'PDV {p}' for p in top_pdvs_plot.index])\n",
    "axes[1, 0].set_title('Top 10 PDVs - Volume Total')\n",
    "axes[1, 0].set_xlabel('Quantidade Total')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# 4. Vendas por trimestre\n",
    "axes[1, 1].bar(vendas_por_trimestre.index, vendas_por_trimestre.values, color=['skyblue', 'lightgreen', 'orange', 'salmon'])\n",
    "axes[1, 1].set_title('Vendas por Trimestre (2022)')\n",
    "axes[1, 1].set_xlabel('Trimestre')\n",
    "axes[1, 1].set_ylabel('Quantidade Total')\n",
    "axes[1, 1].set_xticks(vendas_por_trimestre.index)\n",
    "axes[1, 1].set_xticklabels([f'Q{i}' for i in vendas_por_trimestre.index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ü§ñ Modelagem e Treinamento\n",
    "\n",
    "Vamos construir um modelo de Random Forest para prever as vendas futuras baseado nos padr√µes hist√≥ricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forecast_model(df):\n",
    "    \"\"\"Construir e treinar modelo de forecasting\"\"\"\n",
    "    print(\"ü§ñ CONSTRU√á√ÉO DO MODELO DE FORECASTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Preparar dados para o modelo\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    # Encoders para vari√°veis categ√≥ricas\n",
    "    le_pdv = LabelEncoder()\n",
    "    le_sku = LabelEncoder()\n",
    "    \n",
    "    df_model['pdv_encoded'] = le_pdv.fit_transform(df_model['pdv'])\n",
    "    df_model['sku_encoded'] = le_sku.fit_transform(df_model['sku'])\n",
    "    \n",
    "    # Features adicionais\n",
    "    df_model['trimestre'] = (df_model['semana'] - 1) // 13 + 1\n",
    "    df_model['seno_semana'] = np.sin(2 * np.pi * df_model['semana'] / 52)\n",
    "    df_model['cosseno_semana'] = np.cos(2 * np.pi * df_model['semana'] / 52)\n",
    "    \n",
    "    # Features e target\n",
    "    feature_cols = ['semana', 'trimestre', 'seno_semana', 'cosseno_semana', 'pdv_encoded', 'sku_encoded']\n",
    "    X = df_model[feature_cols]\n",
    "    y = df_model['quantidade']\n",
    "    \n",
    "    # Divis√£o temporal (√∫ltimas 8 semanas para teste)\n",
    "    train_mask = df_model['semana'] <= 44\n",
    "    test_mask = df_model['semana'] > 44\n",
    "    \n",
    "    X_train = X[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_test = y[test_mask]\n",
    "    \n",
    "    print(f\"üìä Dados de treino: {len(X_train):,} registros ({len(X_train)/len(df_model)*100:.1f}%)\")\n",
    "    print(f\"üìä Dados de teste: {len(X_test):,} registros ({len(X_test)/len(df_model)*100:.1f}%)\")\n",
    "    \n",
    "    # Treinar modelo\n",
    "    print(\"\\nüîÑ Treinando modelo Random Forest...\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / np.maximum(y_test, 1))) * 100\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ Modelo treinado com sucesso!\")\n",
    "    print(f\"üìä M√©tricas de Performance:\")\n",
    "    print(f\"   ‚Ä¢ MAE (Erro M√©dio Absoluto): {mae:.2f}\")\n",
    "    print(f\"   ‚Ä¢ RMSE (Erro Quadr√°tico M√©dio): {rmse:.2f}\")\n",
    "    print(f\"   ‚Ä¢ R¬≤ (Coeficiente de Determina√ß√£o): {r2:.4f}\")\n",
    "    print(f\"   ‚Ä¢ MAPE (Erro Percentual M√©dio): {mape:.2f}%\")\n",
    "    \n",
    "    # Salvar encoders no modelo para uso posterior\n",
    "    model.le_pdv = le_pdv\n",
    "    model.le_sku = le_sku\n",
    "    model.feature_cols = feature_cols\n",
    "    model.metrics = metrics\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüîç Feature Importance:\")\n",
    "    for _, row in importance.iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    return model, metrics, (y_test, y_pred)\n",
    "\n",
    "# Treinar o modelo\n",
    "model, metrics, (y_test, y_pred) = build_forecast_model(df_historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise do modelo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('An√°lise do Modelo de Forecasting', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Predito vs Real\n",
    "axes[0, 0].scatter(y_test, y_pred, alpha=0.6)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Valores Reais')\n",
    "axes[0, 0].set_ylabel('Valores Preditos')\n",
    "axes[0, 0].set_title('Predito vs Real')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribui√ß√£o dos res√≠duos\n",
    "residuals = y_test - y_pred\n",
    "axes[0, 1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Res√≠duos')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "axes[0, 1].set_title('Distribui√ß√£o dos Res√≠duos')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--')\n",
    "\n",
    "# 3. Res√≠duos vs Preditos\n",
    "axes[1, 0].scatter(y_pred, residuals, alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Valores Preditos')\n",
    "axes[1, 0].set_ylabel('Res√≠duos')\n",
    "axes[1, 0].set_title('Res√≠duos vs Preditos')\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature Importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': model.feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1, 1].barh(range(len(importance_df)), importance_df['importance'])\n",
    "axes[1, 1].set_yticks(range(len(importance_df)))\n",
    "axes[1, 1].set_yticklabels(importance_df['feature'])\n",
    "axes[1, 1].set_title('Feature Importance')\n",
    "axes[1, 1].set_xlabel('Import√¢ncia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üéØ Gera√ß√£o de Previs√µes para Janeiro 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecasts_2023(model, df_historical):\n",
    "    \"\"\"Gerar previs√µes para as 5 primeiras semanas de janeiro 2023\"\"\"\n",
    "    print(\"üéØ GERA√á√ÉO DE PREVIS√ïES PARA JANEIRO 2023\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    forecasts = []\n",
    "    \n",
    "    # Obter PDVs e SKUs √∫nicos do hist√≥rico\n",
    "    pdvs_unicos = df_historical['pdv'].unique()\n",
    "    skus_unicos = df_historical['sku'].unique()\n",
    "    \n",
    "    print(f\"üìä Gerando previs√µes para:\")\n",
    "    print(f\"   ‚Ä¢ {len(pdvs_unicos)} PDVs\")\n",
    "    print(f\"   ‚Ä¢ {len(skus_unicos)} SKUs\")\n",
    "    print(f\"   ‚Ä¢ 5 semanas de janeiro 2023\")\n",
    "    \n",
    "    total_combinations = len(pdvs_unicos) * len(skus_unicos) * 5\n",
    "    print(f\"   ‚Ä¢ {total_combinations:,} combina√ß√µes totais\")\n",
    "    \n",
    "    print(\"\\nüîÑ Processando previs√µes...\")\n",
    "    \n",
    "    for semana_2023 in range(1, 6):  # Semanas 1-5 de janeiro 2023\n",
    "        print(f\"   Processando semana {semana_2023}...\")\n",
    "        \n",
    "        for pdv in pdvs_unicos:\n",
    "            # Para cada PDV, usar apenas os SKUs que ele historicamente vende\n",
    "            skus_pdv = df_historical[df_historical['pdv'] == pdv]['sku'].unique()\n",
    "            \n",
    "            # Limitar a 30 SKUs principais por PDV para otimiza√ß√£o\n",
    "            if len(skus_pdv) > 30:\n",
    "                top_skus = df_historical[\n",
    "                    df_historical['pdv'] == pdv\n",
    "                ].groupby('sku')['quantidade'].sum().nlargest(30).index\n",
    "                skus_pdv = top_skus.values\n",
    "            \n",
    "            for sku in skus_pdv:\n",
    "                try:\n",
    "                    # Preparar features para predi√ß√£o\n",
    "                    pdv_encoded = model.le_pdv.transform([pdv])[0]\n",
    "                    sku_encoded = model.le_sku.transform([sku])[0]\n",
    "                    trimestre = 1  # Janeiro = Q1\n",
    "                    \n",
    "                    # Features sazonais para janeiro\n",
    "                    seno_semana = np.sin(2 * np.pi * semana_2023 / 52)\n",
    "                    cosseno_semana = np.cos(2 * np.pi * semana_2023 / 52)\n",
    "                    \n",
    "                    X_pred = pd.DataFrame([{\n",
    "                        'semana': semana_2023,\n",
    "                        'trimestre': trimestre,\n",
    "                        'seno_semana': seno_semana,\n",
    "                        'cosseno_semana': cosseno_semana,\n",
    "                        'pdv_encoded': pdv_encoded,\n",
    "                        'sku_encoded': sku_encoded\n",
    "                    }])\n",
    "                    \n",
    "                    # Fazer predi√ß√£o\n",
    "                    pred_qty = model.predict(X_pred[model.feature_cols])[0]\n",
    "                    pred_qty = max(1, int(round(pred_qty)))\n",
    "                    \n",
    "                    forecasts.append({\n",
    "                        'semana': semana_2023,\n",
    "                        'pdv': pdv,\n",
    "                        'produto': sku,\n",
    "                        'quantidade': pred_qty\n",
    "                    })\n",
    "                    \n",
    "                except Exception:\n",
    "                    # Se houver erro, usar m√©dia hist√≥rica\n",
    "                    avg_qty = df_historical[\n",
    "                        (df_historical['pdv'] == pdv) & \n",
    "                        (df_historical['sku'] == sku)\n",
    "                    ]['quantidade'].mean()\n",
    "                    \n",
    "                    if pd.isna(avg_qty):\n",
    "                        avg_qty = df_historical['quantidade'].mean()\n",
    "                    \n",
    "                    forecasts.append({\n",
    "                        'semana': semana_2023,\n",
    "                        'pdv': pdv,\n",
    "                        'produto': sku,\n",
    "                        'quantidade': max(1, int(round(avg_qty)))\n",
    "                    })\n",
    "    \n",
    "    df_forecasts = pd.DataFrame(forecasts)\n",
    "    print(f\"\\n‚úÖ {len(df_forecasts):,} previs√µes geradas com sucesso!\")\n",
    "    \n",
    "    return df_forecasts\n",
    "\n",
    "# Gerar previs√µes\n",
    "forecasts = generate_forecasts_2023(model, df_historical)\n",
    "\n",
    "# Mostrar amostra das previs√µes\n",
    "print(\"\\nüìã Amostra das previs√µes geradas:\")\n",
    "display(forecasts.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üìä An√°lise das Previs√µes Geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_forecasts(df_forecasts):\n",
    "    \"\"\"Analisar as previs√µes geradas\"\"\"\n",
    "    print(\"üìä AN√ÅLISE DAS PREVIS√ïES GERADAS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_previsoes = len(df_forecasts)\n",
    "    total_quantidade = df_forecasts['quantidade'].sum()\n",
    "    media_quantidade = df_forecasts['quantidade'].mean()\n",
    "    mediana_quantidade = df_forecasts['quantidade'].median()\n",
    "    \n",
    "    print(f\"üìä Estat√≠sticas Gerais:\")\n",
    "    print(f\"   ‚Ä¢ Total de previs√µes: {total_previsoes:,}\")\n",
    "    print(f\"   ‚Ä¢ Quantidade total prevista: {total_quantidade:,} unidades\")\n",
    "    print(f\"   ‚Ä¢ M√©dia por previs√£o: {media_quantidade:.1f} unidades\")\n",
    "    print(f\"   ‚Ä¢ Mediana por previs√£o: {mediana_quantidade:.1f} unidades\")\n",
    "    print(f\"   ‚Ä¢ Desvio padr√£o: {df_forecasts['quantidade'].std():.1f}\")\n",
    "    \n",
    "    # An√°lise por semana\n",
    "    print(f\"\\nüìÖ An√°lise por semana (Janeiro 2023):\")\n",
    "    por_semana = df_forecasts.groupby('semana')['quantidade'].agg(['sum', 'count', 'mean']).round(1)\n",
    "    for semana in por_semana.index:\n",
    "        total = por_semana.loc[semana, 'sum']\n",
    "        count = por_semana.loc[semana, 'count']\n",
    "        avg = por_semana.loc[semana, 'mean']\n",
    "        print(f\"   Semana {semana}: {total:,.0f} unidades ({count:,.0f} previs√µes, m√©dia: {avg:.1f})\")\n",
    "    \n",
    "    # Top PDVs previstos\n",
    "    print(f\"\\nüè™ TOP 10 PDVs - Volume Previsto:\")\n",
    "    top_pdvs_pred = df_forecasts.groupby('pdv')['quantidade'].sum().nlargest(10)\n",
    "    for i, (pdv, qty) in enumerate(top_pdvs_pred.items(), 1):\n",
    "        print(f\"   {i:2d}. PDV {pdv}: {qty:,} unidades\")\n",
    "    \n",
    "    # Top SKUs previstos\n",
    "    print(f\"\\nüì¶ TOP 10 Produtos - Volume Previsto:\")\n",
    "    top_skus_pred = df_forecasts.groupby('produto')['quantidade'].sum().nlargest(10)\n",
    "    for i, (sku, qty) in enumerate(top_skus_pred.items(), 1):\n",
    "        print(f\"   {i:2d}. {sku}: {qty:,} unidades\")\n",
    "    \n",
    "    return por_semana, top_pdvs_pred, top_skus_pred\n",
    "\n",
    "# Executar an√°lise\n",
    "semana_stats, top_pdvs_forecast, top_skus_forecast = analyze_forecasts(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes das previs√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('An√°lise das Previs√µes - Janeiro 2023', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Previs√µes por semana\n",
    "semana_totals = forecasts.groupby('semana')['quantidade'].sum()\n",
    "axes[0, 0].bar(semana_totals.index, semana_totals.values, color='skyblue', alpha=0.8)\n",
    "axes[0, 0].set_title('Quantidade Prevista por Semana - Janeiro 2023')\n",
    "axes[0, 0].set_xlabel('Semana')\n",
    "axes[0, 0].set_ylabel('Quantidade Total')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(semana_totals.values):\n",
    "    axes[0, 0].text(i + 1, v + 50, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Top 10 PDVs\n",
    "top_pdvs_plot = top_pdvs_forecast.head(10)\n",
    "axes[0, 1].barh(range(len(top_pdvs_plot)), top_pdvs_plot.values, color='lightgreen', alpha=0.8)\n",
    "axes[0, 1].set_yticks(range(len(top_pdvs_plot)))\n",
    "axes[0, 1].set_yticklabels([f'PDV {int(pdv)}' for pdv in top_pdvs_plot.index])\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].set_title('Top 10 PDVs - Quantidade Total Prevista')\n",
    "axes[0, 1].set_xlabel('Quantidade Total')\n",
    "\n",
    "# 3. Top 10 Produtos\n",
    "top_produtos_plot = top_skus_forecast.head(10)\n",
    "axes[1, 0].barh(range(len(top_produtos_plot)), top_produtos_plot.values, color='salmon', alpha=0.8)\n",
    "axes[1, 0].set_yticks(range(len(top_produtos_plot)))\n",
    "axes[1, 0].set_yticklabels([str(prod) for prod in top_produtos_plot.index])\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].set_title('Top 10 Produtos - Quantidade Total Prevista')\n",
    "axes[1, 0].set_xlabel('Quantidade Total')\n",
    "\n",
    "# 4. Distribui√ß√£o das quantidades previstas\n",
    "axes[1, 1].hist(forecasts['quantidade'], bins=30, alpha=0.7, edgecolor='black', color='orange')\n",
    "axes[1, 1].set_title('Distribui√ß√£o das Quantidades Previstas')\n",
    "axes[1, 1].set_xlabel('Quantidade')\n",
    "axes[1, 1].set_ylabel('Frequ√™ncia')\n",
    "axes[1, 1].axvline(forecasts['quantidade'].mean(), color='red', linestyle='--', label=f'M√©dia: {forecasts[\"quantidade\"].mean():.1f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üíæ Exporta√ß√£o dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar previs√µes em CSV\n",
    "def save_forecasts(df_forecasts, model_metrics):\n",
    "    \"\"\"Salvar previs√µes e m√©tricas do modelo\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Criar diret√≥rio se n√£o existir\n",
    "    import os\n",
    "    os.makedirs('data/processed', exist_ok=True)\n",
    "    \n",
    "    # Arquivo principal de previs√µes\n",
    "    forecast_filename = f\"data/processed/previsoes_janeiro_2023_{timestamp}.csv\"\n",
    "    df_forecasts.to_csv(forecast_filename, index=False)\n",
    "    \n",
    "    # Arquivo de resumo\n",
    "    summary_filename = f\"data/processed/resumo_forecasting_{timestamp}.txt\"
    "    with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"üéØ RELAT√ìRIO DE FORECASTING - ONE-CLICK ORDER\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Data de Gera√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"üìä M√âTRICAS DO MODELO:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for metric, value in model_metrics.items():\n",
    "            f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nüìà RESUMO DAS PREVIS√ïES:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"Total de previs√µes: {len(df_forecasts):,}\\n\")\n",
    "        f.write(f\"Quantidade total prevista: {df_forecasts['quantidade'].sum():,} unidades\\n\")\n",
    "        f.write(f\"M√©dia por previs√£o: {df_forecasts['quantidade'].mean():.1f} unidades\\n\")\n",
    "        f.write(f\"PDVs √∫nicos: {df_forecasts['pdv'].nunique()}\\n\")\n",
    "        f.write(f\"Produtos √∫nicos: {df_forecasts['produto'].nunique()}\\n\\n\")\n",
    "        \n",
    "        f.write(\"üìÖ PREVIS√ïES POR SEMANA:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for semana in sorted(df_forecasts['semana'].unique()):\n",
    "            total = df_forecasts[df_forecasts['semana'] == semana]['quantidade'].sum()\n",
    "            f.write(f\"Semana {semana}: {total:,} unidades\\n\")\n",
    "    \n",
    "    return forecast_filename, summary_filename\n",
    "\n",
    "# Salvar resultados\n",
    "forecast_file, summary_file = save_forecasts(forecasts, model.metrics)\n",
    "\n",
    "print(\"üíæ ARQUIVOS GERADOS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"‚úÖ Previs√µes detalhadas: {forecast_file}\")\n",
    "print(f\"‚úÖ Resumo executivo: {summary_file}\")\n",
    "\n",
    "# Estat√≠sticas finais\n",
    "print(f\"\\nüéä PROCESSO FINALIZADO COM SUCESSO!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä {len(forecasts):,} previs√µes geradas para janeiro 2023\")\n",
    "print(f\"üìà {forecasts['quantidade'].sum():,} unidades totais previstas\")\n",
    "print(f\"üè™ {forecasts['pdv'].nunique()} PDVs cobertos\")\n",
    "print(f\"üì¶ {forecasts['produto'].nunique()} produtos √∫nicos\")\n",
    "print(f\"üéØ Modelo com R¬≤ = {model.metrics['R2']:.4f} e RMSE = {model.metrics['RMSE']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìã PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
    "print(\"1. Validar as previs√µes com a equipe de neg√≥cios\")\n",
    "print(\"2. Ajustar par√¢metros do modelo conforme feedback\")\n",
    "print(\"3. Automatizar pipeline para execu√ß√£o peri√≥dica\")\n",
    "print(\"4. Implementar monitoramento de performance em produ√ß√£o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
